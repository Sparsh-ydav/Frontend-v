{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text file handling and text processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from numpy import array\n",
    "\n",
    "#turn text->token id \n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#to create layers of the model, apply activation functions, create dense and dropout layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, GlobalMaxPooling1D, Embedding, LSTM, Conv1D\n",
    "\n",
    "#divide dataset into train and test sets, and evaluate model performance\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cadce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df = pd.read_csv('IMDB_Dataset.csv', names=['Review', 'Sentiment'], skiprows=1)\n",
    "print(\"\\n Sample of Raw Dataset:\\n\")\n",
    "print(df.sample(10).to_string(index=False))\n",
    "df = df[['Review', 'Sentiment']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8535fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = df['Sentiment'].astype(str).str.strip().str.capitalize()\n",
    "\n",
    "#remove anyhting that is not positve or negstive\n",
    "df = df[df['Sentiment'].isin(['Positive', 'Negative'])]\n",
    "\n",
    "# Update texts AFTER cleaning df\n",
    "texts = df['Review'].astype(str).values\n",
    "\n",
    "# Encode labels\n",
    "labels = df['Sentiment'].map({'Positive': 1, 'Negative': 0}).astype(int).values\n",
    "\n",
    "\n",
    "# Tokenize and Pad\n",
    "vocab_size = 50000\n",
    "maxlen = 500\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Train-Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nSample Preprocessed Data for LSTM Model:\\n\")\n",
    "\n",
    "# Display first 9 examples\n",
    "for i in range(9):\n",
    "    print(f\"Review {i+1}:\")\n",
    "    print(f\"Original Text: {texts[i][:150]}\")\n",
    "    print(f\"Tokenized Sequence (first 10 tokens): {sequences[i][:10]}\")\n",
    "    print(f\"Padded Sequence (first 10 values):    {padded[i][:10]}\")\n",
    "\n",
    "    if labels[i] == 1:\n",
    "        sentiment = \"Positive\"\n",
    "    else:\n",
    "        sentiment = \"Negative\"\n",
    "\n",
    "    print(f\"Label (Encoded): {labels[i]} ({sentiment})\")\n",
    "    print(\"-\" * 80)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc39155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=maxlen))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, maxlen))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8817ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30, batch_size=64, validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7680092",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f127b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt        \n",
    "\n",
    "train_acc = history.history['accuracy']        # list of accuracy per epoch\n",
    "test_acc = accuracy                            # final test accuracy\n",
    "\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Training accuracy line\n",
    "plt.plot(epochs, train_acc, marker='o', label='Training Accuracy')\n",
    "\n",
    "# Test accuracy horizontal line\n",
    "plt.axhline(y=test_acc, color='red', linestyle='-', label='Test Accuracy')\n",
    "\n",
    "plt.title(\"Training Accuracy vs Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
